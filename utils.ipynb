{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba736c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_unique_users(phase, previous_phase=None, user_id_column='user_id'):\n",
    "    \"\"\"\n",
    "    从CSV文件中提取不重复的user_id并保存到新文件\n",
    "    \n",
    "    Parameters:\n",
    "    phase: 比赛阶段\n",
    "    previous_phase: 前一个比赛阶段\n",
    "    user_id_column: user_id列名\n",
    "    \"\"\"\n",
    "    input_file = f'csv_data/inter_{phase}.csv'\n",
    "    previous_phase_file = f'csv_data/inter_{previous_phase}.csv' if previous_phase else None\n",
    "    output_file = f'csv_data/users_{phase}_only.csv'\n",
    "    try:\n",
    "        # 读取数据\n",
    "        df = pd.read_csv(input_file)\n",
    "        previous_phase_df = None\n",
    "        if previous_phase:\n",
    "            previous_phase_df = pd.read_csv(previous_phase_file)\n",
    "        # 提取不重复的user_id\n",
    "        unique_users = df[user_id_column].drop_duplicates().reset_index(drop=True)\n",
    "        unique_users = unique_users[~unique_users.isin(previous_phase_df[user_id_column])] if previous_phase else unique_users\n",
    "        # 创建新DataFrame\n",
    "        result_df = pd.DataFrame({user_id_column: unique_users})\n",
    "        \n",
    "        # 保存到新文件\n",
    "        result_df.to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f\"成功提取 {len(unique_users)} 个不重复用户\")\n",
    "        print(f\"结果已保存到: {output_file}\")\n",
    "        \n",
    "        return result_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"处理过程中出错: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b120360d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功提取 600 个不重复用户\n",
      "结果已保存到: csv_data/users_preliminary_only.csv\n",
      "成功提取 400 个不重复用户\n",
      "结果已保存到: csv_data/users_reevaluation_only.csv\n",
      "成功提取 451 个不重复用户\n",
      "结果已保存到: csv_data/users_final_only.csv\n"
     ]
    }
   ],
   "source": [
    "phase = ['preliminary', 'reevaluation', 'final']\n",
    "for i in range(len(phase)):\n",
    "    extract_unique_users(phase[i],phase[i-1]) if i > 0 else extract_unique_users(phase[i],None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9019a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def process_user_interaction_from_csv(phase):\n",
    "    \n",
    "    map_dict = {\n",
    "        'pre': 'preliminary',\n",
    "        'semi': 'reevaluation',\n",
    "        'final': 'final'\n",
    "    }\n",
    "    # 文件路径配置 - 请根据你的实际情况修改\n",
    "    file_paths = {\n",
    "        'table_a': f'csv_data/users_{map_dict[phase]}_only.csv',  # 用户表\n",
    "        'table_b': 'csv_data/inter_preliminary.csv',  # 交互数据表B\n",
    "        'table_c': 'csv_data/inter_reevaluation.csv',  # 交互数据表C\n",
    "        'table_d': 'csv_data/inter_final.csv'   # 交互数据表D\n",
    "    }\n",
    "\n",
    "    # 输出文件路径\n",
    "    output_file = f'csv_data/interaction_{phase}_only.csv'\n",
    "    \n",
    "    try:\n",
    "        # 1. 从表A读取user_id\n",
    "        print(\"正在从表A读取用户ID...\")\n",
    "        users_df = pd.read_csv(file_paths['table_a'])\n",
    "        \n",
    "        # 检查user_id列是否存在\n",
    "        if 'user_id' not in users_df.columns:\n",
    "            # 尝试常见的用户ID列名\n",
    "            user_id_columns = ['user_id', 'userid', 'userId', 'UserID', '用户ID', '用户编号']\n",
    "            user_id_col = None\n",
    "            for col in user_id_columns:\n",
    "                if col in users_df.columns:\n",
    "                    user_id_col = col\n",
    "                    break\n",
    "            \n",
    "            if user_id_col is None:\n",
    "                raise ValueError(\"未找到用户ID列，请检查CSV文件列名\")\n",
    "        else:\n",
    "            user_id_col = 'user_id'\n",
    "        \n",
    "        user_ids = users_df[user_id_col].tolist()\n",
    "        print(f\"共读取到 {len(user_ids)} 个用户ID\")\n",
    "        \n",
    "        # 2. 从表B、C、D读取交互数据\n",
    "        print(\"正在从表B、C、D读取交互数据...\")\n",
    "        \n",
    "        all_interactions = []\n",
    "        \n",
    "        for table_key in ['table_b', 'table_c', 'table_d']:\n",
    "            print(f\"读取 {table_key}...\")\n",
    "            df = pd.read_csv(file_paths[table_key])\n",
    "            \n",
    "            # 查找用户ID列\n",
    "            user_id_col_interaction = None\n",
    "            for col in ['user_id', 'userid', 'userId', 'UserID', '用户ID', '用户编号']:\n",
    "                if col in df.columns:\n",
    "                    user_id_col_interaction = col\n",
    "                    break\n",
    "            \n",
    "            if user_id_col_interaction is None:\n",
    "                print(f\"警告: {table_key} 中未找到用户ID列，跳过该表\")\n",
    "                continue\n",
    "            \n",
    "            # 查找借阅时间列\n",
    "            borrow_time_col = None\n",
    "            for col in ['borrow_time', 'borrowtime', 'borrowTime', '借阅时间', '时间', 'timestamp']:\n",
    "                if col in df.columns:\n",
    "                    borrow_time_col = col\n",
    "                    break\n",
    "            \n",
    "            # 筛选匹配的用户数据\n",
    "            filtered_df = df[df[user_id_col_interaction].isin(user_ids)].copy()\n",
    "            filtered_df['source_table'] = table_key  # 添加来源表标记\n",
    "            \n",
    "            # 重命名列以便统一处理\n",
    "            if user_id_col_interaction != 'user_id':\n",
    "                filtered_df.rename(columns={user_id_col_interaction: 'user_id'}, inplace=True)\n",
    "            \n",
    "            if borrow_time_col and borrow_time_col != 'borrow_time':\n",
    "                filtered_df.rename(columns={borrow_time_col: 'borrow_time'}, inplace=True)\n",
    "            \n",
    "            all_interactions.append(filtered_df)\n",
    "            print(f\"{table_key} 匹配到 {len(filtered_df)} 条记录\")\n",
    "        \n",
    "        # 3. 合并数据\n",
    "        print(\"正在合并数据...\")\n",
    "        if not all_interactions:\n",
    "            raise ValueError(\"没有找到任何匹配的交互数据\")\n",
    "        \n",
    "        combined_df = pd.concat(all_interactions, ignore_index=True)\n",
    "        print(f\"合并后总数据量: {len(combined_df)} 条\")\n",
    "        \n",
    "        # 4. 按照借阅时间排序并去重\n",
    "        print(\"正在按借阅时间排序并去重...\")\n",
    "        \n",
    "        # 检查是否有借阅时间列\n",
    "        if 'borrow_time' in combined_df.columns:\n",
    "            # 转换借阅时间为datetime格式\n",
    "            combined_df['borrow_time'] = pd.to_datetime(\n",
    "                combined_df['borrow_time'], \n",
    "                errors='coerce'  # 转换失败设为NaT\n",
    "            )\n",
    "            \n",
    "            # 按用户ID和借阅时间排序\n",
    "            combined_df_sorted = combined_df.sort_values(['user_id', 'borrow_time'])\n",
    "            \n",
    "            # 去重 - 根据用户ID和借阅时间完全去重\n",
    "            deduplicated_df = combined_df_sorted.drop_duplicates(\n",
    "                subset=['user_id', 'borrow_time'],  \n",
    "                keep='first'  # 保留第一条记录\n",
    "            )\n",
    "        else:\n",
    "            # 如果没有借阅时间列，只按用户ID去重\n",
    "            print(\"警告: 未找到借阅时间列，仅按用户ID去重\")\n",
    "            combined_df_sorted = combined_df.sort_values('user_id')\n",
    "            deduplicated_df = combined_df_sorted.drop_duplicates(\n",
    "                subset=['user_id'],  \n",
    "                keep='first'\n",
    "            )\n",
    "        \n",
    "        print(f\"去重后数据量: {len(deduplicated_df)} 条\")\n",
    "        \n",
    "        # 5. 写入新CSV文件\n",
    "        print(\"正在写入新CSV文件...\")\n",
    "        deduplicated_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(f\"数据已成功写入文件: {output_file}\")\n",
    "        print(f\"最终数据统计:\")\n",
    "        print(f\"- 总用户数: {deduplicated_df['user_id'].nunique()}\")\n",
    "        print(f\"- 总记录数: {len(deduplicated_df)}\")\n",
    "        \n",
    "        if 'borrow_time' in deduplicated_df.columns:\n",
    "            valid_times = deduplicated_df['borrow_time'].dropna()\n",
    "            if len(valid_times) > 0:\n",
    "                print(f\"- 时间范围: {valid_times.min()} 到 {valid_times.max()}\")\n",
    "        \n",
    "        return deduplicated_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"处理过程中发生错误: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07cd8b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从表A读取用户ID...\n",
      "共读取到 600 个用户ID\n",
      "正在从表B、C、D读取交互数据...\n",
      "读取 table_b...\n",
      "table_b 匹配到 35833 条记录\n",
      "读取 table_c...\n",
      "table_c 匹配到 35881 条记录\n",
      "读取 table_d...\n",
      "table_d 匹配到 35869 条记录\n",
      "正在合并数据...\n",
      "合并后总数据量: 107583 条\n",
      "正在按借阅时间排序并去重...\n",
      "去重后数据量: 44186 条\n",
      "正在写入新CSV文件...\n",
      "数据已成功写入文件: csv_data/interaction_pre_only.csv\n",
      "最终数据统计:\n",
      "- 总用户数: 600\n",
      "- 总记录数: 44186\n",
      "- 时间范围: 2020-01-02 11:16:34 到 2024-12-30 16:37:44\n",
      "正在从表A读取用户ID...\n",
      "共读取到 400 个用户ID\n",
      "正在从表B、C、D读取交互数据...\n",
      "读取 table_b...\n",
      "table_b 匹配到 0 条记录\n",
      "读取 table_c...\n",
      "table_c 匹配到 22446 条记录\n",
      "读取 table_d...\n",
      "table_d 匹配到 22513 条记录\n",
      "正在合并数据...\n",
      "合并后总数据量: 44959 条\n",
      "正在按借阅时间排序并去重...\n",
      "去重后数据量: 26864 条\n",
      "正在写入新CSV文件...\n",
      "数据已成功写入文件: csv_data/interaction_semi_only.csv\n",
      "最终数据统计:\n",
      "- 总用户数: 400\n",
      "- 总记录数: 26864\n",
      "- 时间范围: 2020-01-02 10:13:48 到 2024-12-30 14:38:15\n",
      "正在从表A读取用户ID...\n",
      "共读取到 451 个用户ID\n",
      "正在从表B、C、D读取交互数据...\n",
      "读取 table_b...\n",
      "table_b 匹配到 0 条记录\n",
      "读取 table_c...\n",
      "table_c 匹配到 0 条记录\n",
      "读取 table_d...\n",
      "table_d 匹配到 23928 条记录\n",
      "正在合并数据...\n",
      "合并后总数据量: 23928 条\n",
      "正在按借阅时间排序并去重...\n",
      "去重后数据量: 23858 条\n",
      "正在写入新CSV文件...\n",
      "数据已成功写入文件: csv_data/interaction_final_only.csv\n",
      "最终数据统计:\n",
      "- 总用户数: 451\n",
      "- 总记录数: 23858\n",
      "- 时间范围: 2020-01-02 12:20:22 到 2024-12-30 16:14:11\n"
     ]
    }
   ],
   "source": [
    "phases = ['pre', 'semi', 'final']\n",
    "for phase in phases:\n",
    "    process_user_interaction_from_csv(phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9b679be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "def process_data_to_recbole(phase):\n",
    "\n",
    "    DATA_DIR = f'./dataset/library_data_{phase}'\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    print(f\"数据输出目录已创建/检查: {DATA_DIR}\")\n",
    "\n",
    "    FILE_PREFIX = f'library_data_{phase}'\n",
    "\n",
    "    try:\n",
    "        df_book = pd.read_csv('./csv_data/item.csv')\n",
    "        df_inter = pd.read_csv(f'./csv_data/interaction_{phase}_only.csv')\n",
    "        df_user = pd.read_csv('./csv_data/user.csv')\n",
    "        print(\"原始文件加载成功。\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"错误：未能找到文件，请检查路径。缺失文件: {e}\")\n",
    "    \n",
    "    print(\"\\n--- 3. 正在处理交互文件 (inter.csv) ---\")\n",
    "    \n",
    "    inter_data = df_inter[['user_id', 'book_id', 'borrow_time']].copy()\n",
    "    \n",
    "    inter_data.rename(columns={\n",
    "        'user_id': 'user_id:token',\n",
    "        'book_id': 'item_id:token',\n",
    "        'borrow_time': 'timestamp:float'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    inter_data['timestamp:float'] = inter_data['timestamp:float'].apply(\n",
    "        lambda x: time.mktime(time.strptime(str(x), '%Y-%m-%d %H:%M:%S'))\n",
    "    )\n",
    "    \n",
    "    inter_data['label:float'] = 1.0\n",
    "    \n",
    "    # === 添加打乱操作 ===\n",
    "    print(\"正在打乱交互数据...\")\n",
    "    inter_data = inter_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    print(f\"打乱完成，共 {len(inter_data)} 条交互记录\")\n",
    "    \n",
    "    inter_output_path = os.path.join(DATA_DIR, f'{FILE_PREFIX}.inter')\n",
    "    inter_data.to_csv(inter_output_path, sep='\\t', index=False)\n",
    "    print(f\"交互文件已保存至: {inter_output_path}\")\n",
    "    \n",
    "    # --- 4. 处理 BOOK.CSV -> library_data.item ---\n",
    "    \n",
    "    print(\"\\n--- 4. 正在处理物品文件 (book.csv) ---\")\n",
    "    \n",
    "    item_data = df_book.copy()\n",
    "    \n",
    "    item_data.rename(columns={\n",
    "        'book_id': 'item_id:token',\n",
    "        '题名': 'title:token',\n",
    "        '作者': 'author:token',\n",
    "        '出版社': 'publisher:token',\n",
    "        '一级分类': 'category_l1:token',\n",
    "        '二级分类': 'category_l2:token'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    item_output_path = os.path.join(DATA_DIR, f'{FILE_PREFIX}.item')\n",
    "    item_data.to_csv(item_output_path, sep='\\t', index=False)\n",
    "    print(f\"物品文件已保存至: {item_output_path}\")\n",
    "    \n",
    "    # --- 5. 处理 USER.CSV -> library_data.user ---\n",
    "    \n",
    "    print(\"\\n--- 5. 正在处理用户文件 (user.csv) ---\")\n",
    "    \n",
    "    active_user_ids = set(df_inter['user_id'].unique())\n",
    "    print(f\"交互数据中共有 {len(active_user_ids)} 个活跃用户\")\n",
    "    \n",
    "    # user_data = df_user[df_user['借阅人'].isin(active_user_ids)].copy()\n",
    "    user_data = df_user.copy()\n",
    "    print(f\"过滤后用户数据包含 {len(user_data)} 个用户\")\n",
    "    \n",
    "    # 5.3 核心列重命名和标记\n",
    "    user_data.rename(columns={\n",
    "        '借阅人': 'user_id:token',\n",
    "        '性别': 'gender:token',\n",
    "        'DEPT': 'dept:token',\n",
    "        '年级': 'grade:token',\n",
    "        '类型': 'user_type:token'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    user_output_path = os.path.join(DATA_DIR, f'{FILE_PREFIX}.user')\n",
    "    user_data.to_csv(user_output_path, sep='\\t', index=False)\n",
    "    print(f\"用户文件已保存至: {user_output_path}\")\n",
    "    \n",
    "    print(\"\\n--- 6. 数据一致性检查 ---\")\n",
    "    \n",
    "    inter_user_ids = set(inter_data['user_id:token'])\n",
    "    user_file_ids = set(user_data['user_id:token'])\n",
    "    \n",
    "    missing_in_user = inter_user_ids - user_file_ids\n",
    "    extra_in_user = user_file_ids - inter_user_ids\n",
    "    \n",
    "    print(f\"交互文件中的用户数量: {len(inter_user_ids)}\")\n",
    "    print(f\"用户文件中的用户数量: {len(user_file_ids)}\")\n",
    "    print(f\"只在交互文件中出现的用户: {len(missing_in_user)}\")\n",
    "    print(f\"只在用户文件中出现的用户: {len(extra_in_user)}\")\n",
    "    \n",
    "    if missing_in_user:\n",
    "        print(f\"警告：以下用户出现在交互数据但不在用户数据中: {list(missing_in_user)[:5]}...\")  # 只显示前5个\n",
    "    if extra_in_user:\n",
    "        print(f\"警告：以下用户出现在用户数据但不在交互数据中: {list(extra_in_user)[:5]}...\")  # 只显示前5个\n",
    "    \n",
    "    print(\"\\n==================================\")\n",
    "    print(\"RecBole 数据文件生成完毕！\")\n",
    "    print(\"您已经成功创建了以下文件，可直接用于 RecBole 训练：\")\n",
    "    print(f\"- {inter_output_path}\")\n",
    "    print(f\"- {item_output_path}\")\n",
    "    print(f\"- {user_output_path}\")\n",
    "    print(\"==================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ebddd1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据输出目录已创建/检查: ./dataset/library_data_pre\n",
      "原始文件加载成功。\n",
      "\n",
      "--- 3. 正在处理交互文件 (inter.csv) ---\n",
      "正在打乱交互数据...\n",
      "打乱完成，共 44186 条交互记录\n",
      "交互文件已保存至: ./dataset/library_data_pre/library_data_pre.inter\n",
      "\n",
      "--- 4. 正在处理物品文件 (book.csv) ---\n",
      "物品文件已保存至: ./dataset/library_data_pre/library_data_pre.item\n",
      "\n",
      "--- 5. 正在处理用户文件 (user.csv) ---\n",
      "交互数据中共有 600 个活跃用户\n",
      "过滤后用户数据包含 1451 个用户\n",
      "用户文件已保存至: ./dataset/library_data_pre/library_data_pre.user\n",
      "\n",
      "--- 6. 数据一致性检查 ---\n",
      "交互文件中的用户数量: 600\n",
      "用户文件中的用户数量: 1451\n",
      "只在交互文件中出现的用户: 0\n",
      "只在用户文件中出现的用户: 851\n",
      "警告：以下用户出现在用户数据但不在交互数据中: [3, 5, 7, 12, 13]...\n",
      "\n",
      "==================================\n",
      "RecBole 数据文件生成完毕！\n",
      "您已经成功创建了以下文件，可直接用于 RecBole 训练：\n",
      "- ./dataset/library_data_pre/library_data_pre.inter\n",
      "- ./dataset/library_data_pre/library_data_pre.item\n",
      "- ./dataset/library_data_pre/library_data_pre.user\n",
      "==================================\n",
      "数据输出目录已创建/检查: ./dataset/library_data_semi\n",
      "原始文件加载成功。\n",
      "\n",
      "--- 3. 正在处理交互文件 (inter.csv) ---\n",
      "正在打乱交互数据...\n",
      "打乱完成，共 26864 条交互记录\n",
      "交互文件已保存至: ./dataset/library_data_semi/library_data_semi.inter\n",
      "\n",
      "--- 4. 正在处理物品文件 (book.csv) ---\n",
      "物品文件已保存至: ./dataset/library_data_semi/library_data_semi.item\n",
      "\n",
      "--- 5. 正在处理用户文件 (user.csv) ---\n",
      "交互数据中共有 400 个活跃用户\n",
      "过滤后用户数据包含 1451 个用户\n",
      "用户文件已保存至: ./dataset/library_data_semi/library_data_semi.user\n",
      "\n",
      "--- 6. 数据一致性检查 ---\n",
      "交互文件中的用户数量: 400\n",
      "用户文件中的用户数量: 1451\n",
      "只在交互文件中出现的用户: 0\n",
      "只在用户文件中出现的用户: 1051\n",
      "警告：以下用户出现在用户数据但不在交互数据中: [1, 2, 4, 6, 7]...\n",
      "\n",
      "==================================\n",
      "RecBole 数据文件生成完毕！\n",
      "您已经成功创建了以下文件，可直接用于 RecBole 训练：\n",
      "- ./dataset/library_data_semi/library_data_semi.inter\n",
      "- ./dataset/library_data_semi/library_data_semi.item\n",
      "- ./dataset/library_data_semi/library_data_semi.user\n",
      "==================================\n",
      "数据输出目录已创建/检查: ./dataset/library_data_final\n",
      "原始文件加载成功。\n",
      "\n",
      "--- 3. 正在处理交互文件 (inter.csv) ---\n",
      "正在打乱交互数据...\n",
      "打乱完成，共 23858 条交互记录\n",
      "交互文件已保存至: ./dataset/library_data_final/library_data_final.inter\n",
      "\n",
      "--- 4. 正在处理物品文件 (book.csv) ---\n",
      "物品文件已保存至: ./dataset/library_data_final/library_data_final.item\n",
      "\n",
      "--- 5. 正在处理用户文件 (user.csv) ---\n",
      "交互数据中共有 451 个活跃用户\n",
      "过滤后用户数据包含 1451 个用户\n",
      "用户文件已保存至: ./dataset/library_data_final/library_data_final.user\n",
      "\n",
      "--- 6. 数据一致性检查 ---\n",
      "交互文件中的用户数量: 451\n",
      "用户文件中的用户数量: 1451\n",
      "只在交互文件中出现的用户: 0\n",
      "只在用户文件中出现的用户: 1000\n",
      "警告：以下用户出现在用户数据但不在交互数据中: [1, 2, 3, 4, 5]...\n",
      "\n",
      "==================================\n",
      "RecBole 数据文件生成完毕！\n",
      "您已经成功创建了以下文件，可直接用于 RecBole 训练：\n",
      "- ./dataset/library_data_final/library_data_final.inter\n",
      "- ./dataset/library_data_final/library_data_final.item\n",
      "- ./dataset/library_data_final/library_data_final.user\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "for phase in phases:\n",
    "    process_data_to_recbole(phase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pnpl",
   "language": "python",
   "name": "pnpl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
